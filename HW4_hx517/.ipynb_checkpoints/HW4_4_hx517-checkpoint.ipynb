{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "# Skeleton of Assignment 4:\n",
    "    test if the distribution of \n",
    "    \n",
    "    1) trip duration of bikers that ride during the day vs night\n",
    "    \n",
    "    2) age of bikers for trips originating in Manhattan and in Brooklyn\n",
    "    \n",
    "    are different. Use 3 tests: KS, Pearson's, Spearman's. \n",
    "    \n",
    "    Use the scipy.stats functions scipy.stats.ks_2samp, scipy.stats.pearsonr, scipy.stats.spearmanr. \n",
    "    \n",
    "    For the KS do the test with the entire dataset and with a subset 200 times smaller\n",
    "    \n",
    "    Choose a single significant threshold for the whole exercise. \n",
    "    \n",
    "    For each test phrase the Null Hypothesis in words.\n",
    "    \n",
    "    Describe the return of the scipy function you use in each case.\n",
    "    \n",
    "    State the result in terms of rejection of the Null."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-05T16:48:06.390950",
     "start_time": "2017-10-05T16:48:04.815178"
    },
    "collapsed": false,
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "# my usual imports and setups\n",
    "import pylab as pl\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "#imports downloader\n",
    "from getCitiBikeCSV import getCitiBikeCSV\n",
    "\n",
    "%pylab inline\n",
    "\n",
    "import os\n",
    "#this makes my plots pretty! but it is totally not mandatory to do it\n",
    "import json\n",
    "#s = json.load( open(os.getenv ('PUI2016')+\"/fbb_matplotlibrc.json\") )\n",
    "#pl.rcParams.update(s)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "# Read in data\n",
    "You are requested to use 2 months at least. It would be a good idea to use data from a colder and a warmer months, since there are more riders in the warm weather and ridership patterns may change with weather, temperature, etc. You should use data from multiple months, joining multiple datasets (thus addressing some systematic errors as well)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-05T16:48:09.386484",
     "start_time": "2017-10-05T16:48:06.821336"
    },
    "collapsed": false,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Downloading', '201501')\n",
      "file in place, you can continue\n"
     ]
    }
   ],
   "source": [
    "datestring = '201501'\n",
    "getCitiBikeCSV(datestring)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-05T16:48:11.528975",
     "start_time": "2017-10-05T16:48:10.267002"
    },
    "collapsed": false,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tripduration</th>\n",
       "      <th>starttime</th>\n",
       "      <th>stoptime</th>\n",
       "      <th>start station id</th>\n",
       "      <th>start station name</th>\n",
       "      <th>start station latitude</th>\n",
       "      <th>start station longitude</th>\n",
       "      <th>end station id</th>\n",
       "      <th>end station name</th>\n",
       "      <th>end station latitude</th>\n",
       "      <th>end station longitude</th>\n",
       "      <th>bikeid</th>\n",
       "      <th>usertype</th>\n",
       "      <th>birth year</th>\n",
       "      <th>gender</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1346</td>\n",
       "      <td>1/1/2015 0:01</td>\n",
       "      <td>1/1/2015 0:24</td>\n",
       "      <td>455</td>\n",
       "      <td>1 Ave &amp; E 44 St</td>\n",
       "      <td>40.750020</td>\n",
       "      <td>-73.969053</td>\n",
       "      <td>265</td>\n",
       "      <td>Stanton St &amp; Chrystie St</td>\n",
       "      <td>40.722293</td>\n",
       "      <td>-73.991475</td>\n",
       "      <td>18660</td>\n",
       "      <td>Subscriber</td>\n",
       "      <td>1960.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>363</td>\n",
       "      <td>1/1/2015 0:02</td>\n",
       "      <td>1/1/2015 0:08</td>\n",
       "      <td>434</td>\n",
       "      <td>9 Ave &amp; W 18 St</td>\n",
       "      <td>40.743174</td>\n",
       "      <td>-74.003664</td>\n",
       "      <td>482</td>\n",
       "      <td>W 15 St &amp; 7 Ave</td>\n",
       "      <td>40.739355</td>\n",
       "      <td>-73.999318</td>\n",
       "      <td>16085</td>\n",
       "      <td>Subscriber</td>\n",
       "      <td>1963.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>346</td>\n",
       "      <td>1/1/2015 0:04</td>\n",
       "      <td>1/1/2015 0:10</td>\n",
       "      <td>491</td>\n",
       "      <td>E 24 St &amp; Park Ave S</td>\n",
       "      <td>40.740964</td>\n",
       "      <td>-73.986022</td>\n",
       "      <td>505</td>\n",
       "      <td>6 Ave &amp; W 33 St</td>\n",
       "      <td>40.749013</td>\n",
       "      <td>-73.988484</td>\n",
       "      <td>20845</td>\n",
       "      <td>Subscriber</td>\n",
       "      <td>1974.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>182</td>\n",
       "      <td>1/1/2015 0:04</td>\n",
       "      <td>1/1/2015 0:07</td>\n",
       "      <td>384</td>\n",
       "      <td>Fulton St &amp; Waverly Ave</td>\n",
       "      <td>40.683178</td>\n",
       "      <td>-73.965964</td>\n",
       "      <td>399</td>\n",
       "      <td>Lafayette Ave &amp; St James Pl</td>\n",
       "      <td>40.688515</td>\n",
       "      <td>-73.964763</td>\n",
       "      <td>19610</td>\n",
       "      <td>Subscriber</td>\n",
       "      <td>1969.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>969</td>\n",
       "      <td>1/1/2015 0:05</td>\n",
       "      <td>1/1/2015 0:21</td>\n",
       "      <td>474</td>\n",
       "      <td>5 Ave &amp; E 29 St</td>\n",
       "      <td>40.745168</td>\n",
       "      <td>-73.986831</td>\n",
       "      <td>432</td>\n",
       "      <td>E 7 St &amp; Avenue A</td>\n",
       "      <td>40.726218</td>\n",
       "      <td>-73.983799</td>\n",
       "      <td>20197</td>\n",
       "      <td>Subscriber</td>\n",
       "      <td>1977.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   tripduration      starttime       stoptime  start station id  \\\n",
       "0          1346  1/1/2015 0:01  1/1/2015 0:24               455   \n",
       "1           363  1/1/2015 0:02  1/1/2015 0:08               434   \n",
       "2           346  1/1/2015 0:04  1/1/2015 0:10               491   \n",
       "3           182  1/1/2015 0:04  1/1/2015 0:07               384   \n",
       "4           969  1/1/2015 0:05  1/1/2015 0:21               474   \n",
       "\n",
       "        start station name  start station latitude  start station longitude  \\\n",
       "0          1 Ave & E 44 St               40.750020               -73.969053   \n",
       "1          9 Ave & W 18 St               40.743174               -74.003664   \n",
       "2     E 24 St & Park Ave S               40.740964               -73.986022   \n",
       "3  Fulton St & Waverly Ave               40.683178               -73.965964   \n",
       "4          5 Ave & E 29 St               40.745168               -73.986831   \n",
       "\n",
       "   end station id             end station name  end station latitude  \\\n",
       "0             265     Stanton St & Chrystie St             40.722293   \n",
       "1             482              W 15 St & 7 Ave             40.739355   \n",
       "2             505              6 Ave & W 33 St             40.749013   \n",
       "3             399  Lafayette Ave & St James Pl             40.688515   \n",
       "4             432            E 7 St & Avenue A             40.726218   \n",
       "\n",
       "   end station longitude  bikeid    usertype  birth year  gender  \n",
       "0             -73.991475   18660  Subscriber      1960.0       2  \n",
       "1             -73.999318   16085  Subscriber      1963.0       1  \n",
       "2             -73.988484   20845  Subscriber      1974.0       1  \n",
       "3             -73.964763   19610  Subscriber      1969.0       1  \n",
       "4             -73.983799   20197  Subscriber      1977.0       1  "
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(os.getenv(\"PUIDATA\") + \"/\" + datestring + '-citibike-tripdata.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-05T16:51:52.008367",
     "start_time": "2017-10-05T16:48:18.977948"
    },
    "collapsed": false,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "# df is the dataframe where the content of the csv file is stored\n",
    "df['date'] = pd.to_datetime(df['starttime'])\n",
    "# note that with dataframes I can refer to variables as dictionary keys, \n",
    "# i.e. df['starttime'] or as attributes: df.starttime. \n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "# 0. Sample\n",
    "# SPLIT BY CATEGORY\n",
    "\n",
    "as an example I am splitting data by gender and looking at age or riders:\n",
    "\n",
    "**H0: there is no statistical difference in the age distribution of male and female riders**\n",
    "$$ \\alpha = 0.05 $$\n",
    "\n",
    "extracting the age happens in the cell below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-05T16:51:52.357332",
     "start_time": "2017-10-05T16:51:52.017199"
    },
    "collapsed": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "#df is the dataframe where the content of the csv file is stored\n",
    "df['ageM'] = 2015 - df['birth year'][(df['usertype'] == 'Subscriber') & (df['gender'] == 1)]\n",
    "df['ageF'] = 2015 - df['birth year'][(df['usertype'] == 'Subscriber') & (df['gender'] == 2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "#dropping some data I no longer need\n",
    "#... your code here...\n",
    "df_KS = df.drop([u'tripduration', u'starttime', u'stoptime', u'start station id',\n",
    "       u'start station name', u'start station latitude',\n",
    "       u'start station longitude', u'end station id', u'end station name',\n",
    "       u'end station latitude', u'end station longitude', u'bikeid',\n",
    "       u'usertype', u'birth year',  u'date'],axis=1)\n",
    "df_KS.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-05T16:55:03.392271",
     "start_time": "2017-10-05T16:55:02.902521"
    },
    "collapsed": false,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "#your df should look something like this\n",
    "# look at these data carefully... you may see someinteresting values!\n",
    "df_KS.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-05T16:55:05.649685",
     "start_time": "2017-10-05T16:55:05.635796"
    },
    "collapsed": false,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "# dropping NaN values\n",
    "df_KS['ageM'].dropna(inplace= True)\n",
    "df_KS['ageF'].dropna(inplace= True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "lets split age in 10 year bins. the dataset is very large, so i could be split in smaller bins, but I will chose 10 years in the interest of time. \n",
    "the bin size choice should be a balance between properly sample the age space, have enough counts in each bin that the statistical noise is not significant (remember that is > sqrt(N)!) and the computational requirement to computatinal facilities ratio. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "the next several steps are needed if you want to code up the KS test from scratch. that is for extra credit, so if you do not want to do it you may not need to plot split the distribution in bins and create the cumulative HOWEVER it is a great idea to do it anyways to explore your data viaually! remember Ascombe's quartet!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-05T16:55:21.602238",
     "start_time": "2017-10-05T16:55:20.487384"
    },
    "collapsed": false,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "# plotting histogramswith pandas is a bitdifferent than with pylab\n",
    "# this is a VERY USEFUL syntaxfor you to knonw!\n",
    "bins = np.arange(10, 99, 5)\n",
    "axM = df_KS.ageM.groupby(pd.cut(df_KS.ageM, bins)).agg([count_nonzero]).plot(kind='bar', \n",
    "                                                                legend=False)\n",
    "axM.set_title(\"male riders\")\n",
    "axF = df_KS.ageF.groupby(pd.cut(df_KS.ageF, bins)).agg([count_nonzero]).plot(kind='bar',\n",
    "                                                                legend=False)\n",
    "axF.set_title(\"female riders\");\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "**Figure 1: histogrammed distribution of riders' ages by gender **\n",
    "here is where you should have a nice caption that describes what I am looking at, why I am looking at it, and what I should notice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "this is how the cumulative distributions look like.  Notice that i am normalizing them! if i want to reat an observed distribution like a probablility distribution i have to normalize it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#print df.ageS, df.ageS.cumsum()\n",
    "\n",
    "csM=df_KS.ageM.groupby(pd.cut(df_KS.ageM, bins)).agg([count_nonzero]).cumsum()\n",
    "\n",
    "csF=df_KS.ageF.groupby(pd.cut(df_KS.ageF, bins)).agg([count_nonzero]).cumsum()\n",
    "\n",
    "print (np.abs(csM / csM.max()-csF / csF.max()))\n",
    "\n",
    "pl.plot(bins[:-1] + 5, csM / csM.max(), label = \"M\")\n",
    "pl.plot(bins[:-1] + 5, csF / csF.max(), label = \"F\")\n",
    "pl.plot(bins[:-1] + 5, np.sqrt(csF / csF.max() - csM / csM.max())**2, 'k-',\n",
    "        label = \"difference\")\n",
    "pl.xlabel(\"Age\")\n",
    "pl.ylabel(\"Normalized Cumulative Number\")\n",
    "pl.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "** Figure 2: the cumulative distribution of CitiBike riders' ages by gender** ... [a good caption here]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "They look similar! But the difference gets to 10%. If I wanted to code the KS test by hand I woud have everything I need: the normalized cumulative distributions can be subtracted from each other and the max distance can calculated. \n",
    "\n",
    "Notice that there may be NaN values you are gonna have to deal with! \n",
    "You can do that for example with a Boolean statementsuch as  df.ageF[~np.isnan(df.ageF)] or you can use numpy functions that deal with Nan values: nansum, nanmean, nanstd..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "lets run the scipy KS test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-05T16:58:02.949986",
     "start_time": "2017-10-05T16:58:02.443596"
    },
    "collapsed": false,
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import scipy.stats\n",
    "#remember that your imports should all be at the top. I leave it here to hightlight that this package is needed at this point of the workflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "# 0.1 KS tests to compare 2 samples\n",
    "\n",
    "http://docs.scipy.org/doc/scipy-0.15.1/reference/generated/scipy.stats.ks_2samp.html\n",
    "\n",
    "the KS test in scipy returns the p-value BUT make sure you understand what the NULL is! read the documentation carefully! what is the null hypothesis that you can/cannot reject?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-05T16:58:13.968035",
     "start_time": "2017-10-05T16:58:13.899033"
    },
    "collapsed": false,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "ks = scipy.stats.ks_2samp(df_KS.ageM, df_KS.ageF)\n",
    "print (ks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "**  FILL IN THE CELL BELOW!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-05T16:58:24.751556",
     "start_time": "2017-10-05T16:58:24.747653"
    },
    "collapsed": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "##### your words here!...\n",
    "##### this cell is for you to tell me what the scipy KS test returned and what it means in terms of NULL HYPOTHESIS\n",
    "##### to do that refer to the scipy documentation to understand the output of the scipy.stats.ks_2samp function\n",
    "### KS statistic = 0.06744\n",
    "### p-value = 4.0408611999082294e-168\n",
    "### So reject the null hypothesis since the p-value is less than critical value 0.05.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "The scipy.stats KS test already tells me the significance and the p-value. \n",
    "\n",
    "The next few cells are here just to show you how you would obtain the same result by hand, but they are **not required**. \n",
    "\n",
    "Remember: the Null hypothesis is rejected if \n",
    "\n",
    "$D_KS(n1,n2) > c(\\alpha) \\sqrt{\\frac{(n1 + n2)}{n1n2}}$\n",
    "\n",
    "(see class notes) where $c(\\alpha$) is the inverse of the KS distribution, and you do not have to know how to get that cause there are tables that list critical values!! \n",
    "\n",
    "http://www.real-statistics.com/tests-normality-and-symmetry/statistical-tests-normality-symmetry/kolmogorov-smirnov-test/kolmogorov-distribution/\n",
    "\n",
    "But also this result depends in your choice of binning through, and thustheresultyou get by hand may not be exactly the same as the one the KS returns. Either way: this is how you would calculate the KS statistics by hand."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-05T16:58:33.858841",
     "start_time": "2017-10-05T16:58:33.850240"
    },
    "collapsed": false,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "#here is the critical values tablel. Have you chosen your significance level yet?? you should do it first thing!\n",
    "from IPython.display import Image\n",
    "Image(\"https://raw.githubusercontent.com/fedhere/PUI2017_fb55/master/plotsforclasses/ks2sample_table.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0.2 Redo the KS test with reducted dataset (a subset 200 times smaller)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-05T16:58:45.489436",
     "start_time": "2017-10-05T16:58:45.483526"
    },
    "collapsed": false,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "## your words here!...\n",
    "## this cell is for you to redo the test with reducted dataset \n",
    "## and tell me what the scipy ks test returned and what it means in terms of NULL HYPOTHESIS\n",
    "\n",
    "\n",
    "df_KS_sub = df_KS.sample(n=int(len(df_KS)/200),random_state=500)\n",
    "\n",
    "len(df_KS_sub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bins = np.arange(10, 99, 5)\n",
    "axM = df_KS_sub.ageM.groupby(pd.cut(df_KS_sub.ageM, bins)).agg([count_nonzero]).plot(kind='bar', \n",
    "                                                                legend=False)\n",
    "axM.set_title(\"male riders\")\n",
    "axF = df_KS_sub.ageF.groupby(pd.cut(df_KS_sub.ageF, bins)).agg([count_nonzero]).plot(kind='bar',\n",
    "                                                                legend=False)\n",
    "axF.set_title(\"female riders\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Figure 3: histogrammed distribution of riders' ages by gender**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#print df.ageS, df.ageS.cumsum()\n",
    "\n",
    "csM=df_KS_sub.ageM.groupby(pd.cut(df_KS_sub.ageM, bins)).agg([count_nonzero]).cumsum()\n",
    "\n",
    "csF=df_KS_sub.ageF.groupby(pd.cut(df_KS_sub.ageF, bins)).agg([count_nonzero]).cumsum() \n",
    "\n",
    "print (np.abs(csM / csM.max()-csF / csF.max()))\n",
    "\n",
    "pl.plot(bins[:-1] + 5, csM / csM.max(), label = \"M\")\n",
    "pl.plot(bins[:-1] + 5, csF / csF.max(), label = \"F\")\n",
    "pl.plot(bins[:-1] + 5, np.sqrt(csF / csF.max() - csM / csM.max())**2, 'k-',\n",
    "        label = \"difference\")\n",
    "pl.xlabel(\"Age\")\n",
    "pl.ylabel(\"Normalized Cumulative Number\")\n",
    "pl.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "# Now retest using a test for correlation. \n",
    "\n",
    "That will answer a slightly different question though - formulate the NULL appropriately. The tests for correlations (generally) requires the variable to be paired, so that I can tell if x changes does y change similarly. But the datasets are of different size! You will need to reduce them to the same size. You can do that by subsampling of the data: take only 1 ride every of 200, which you can achieve \"slicing and broadcasting\" the array or using one of the python function (built in python numpy.random.choice() functions for example: Docstring:\n",
    "choice(a, size=None, replace=True, p=None)\n",
    "\n",
    "Generates a random sample from a given 1-D array\n",
    "\n",
    "        .. versionadded:: 1.7.0\n",
    "\n",
    "Parameters\n",
    "...\n",
    "\n",
    "But make sure you understand how to use it! there is an option \"replace\" which you should think about."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_sub_m = np.random.choice(df_KS['ageM'].dropna(),size=df_KS['ageF'].count())\n",
    "df_sub_f = df_KS['ageF'].dropna()\n",
    "\n",
    "df_sub = pd.DataFrame([df_sub_m,df_sub_f]).T\n",
    "df_sub.columns = ['Male','Female']\n",
    "\n",
    "df_sub['Male'] = df_sub['Male'].sort_values().values\n",
    "df_sub['Female'] = df_sub['Female'].sort_values().values\n",
    "\n",
    "df_sub.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "# 0.3 Pearson's  test for correlation\n",
    "\n",
    "** notice that the Pearson's is a pairwise test: the samples need to be **\n",
    " a. the same size\n",
    " b. sorted! (how??)\n",
    "    \n",
    "http://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.pearsonr.html#scipy.stats.pearsonr\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-05T17:05:04.485128",
     "start_time": "2017-10-05T17:05:04.480928"
    },
    "collapsed": false,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "# your code here!\n",
    "# wrangle the data as needed\n",
    "# please perform the Pearson's test \n",
    "# and tell me what you find in terms of NULL hypothesis\n",
    "\n",
    "pr = scipy.stats.pearsonr(df_sub.Male,df_sub.Female)\n",
    "print(pr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Discussion:\n",
    "**Pearson’s correlation coefficient = 0.99511**  \n",
    "**p-value = 0.0**  \n",
    "**so reject the null hypothesis because the p value is below 0.05**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "# 0.3 Spearman's  test for correlation\n",
    "\n",
    "http://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.spearmanr.html#scipy.stats.spearmanr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-05T17:05:09.530148",
     "start_time": "2017-10-05T17:05:09.525214"
    },
    "collapsed": false,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "# your code here!\n",
    "# wrangle the data as needed\n",
    "# please perform the Spearman's test and tell me what you find in terms of NULL hypothesis\n",
    "spr = scipy.stats.spearmanr(df_sub.Male,df_sub.Female)\n",
    "print(spr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Discussion:\n",
    "**Spearman’s correlation coefficient = 0.9991**  \n",
    "**p-value = 0.0**  \n",
    "**so reject the null hypothesis because the p value is below 0.05**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Choose 201701 and 201707 as Sample for next two tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def download(datestring):\n",
    "    #getCitiBikeCSV(datestring)\n",
    "    os.system(\"curl -O https://s3.amazonaws.com/tripdata/\" + datestring + \"-citibike-tripdata.csv.zip\")\n",
    "    ###  To move it I use the os.system() functions to run bash commands with arguments\n",
    "    os.system(\"mv \" + datestring + \"-citibike-tripdata.csv.zip \" + os.getenv(\"PUIDATA\"))\n",
    "    ### unzip the csv \n",
    "    os.system(\"unzip \" + os.getenv(\"PUIDATA\") + \"/\" + datestring + \"-citibike-tripdata..csvzip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "download('201701')\n",
    "download('201706')\n",
    "\n",
    "dfA = pd.read_csv(os.getenv(\"PUIDATA\") + \"/201701-citibike-tripdata.csv.zip\")\n",
    "dfB = pd.read_csv(os.getenv(\"PUIDATA\") + \"/201706-citibike-tripdata.csv.zip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dfA['date'] = pd.to_datetime(dfA['starttime'])\n",
    "dfB['date'] = pd.to_datetime(dfB['starttime'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dfC = pd.concat([dfA,dfB],ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "## 1. trip duration of bikers during the day vs night"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### H0: there is no statistical difference in the trip duration distribution of bikers that ride during the day (8 am to 8 pm) vs night (8 pm to 8 am)\n",
    "##### $\\alpha$ = 0.05"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Split by category\n",
    "split data by day time (8 am to 8pm) and night time (8 pm to 8 am)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dfC.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dfC.groupby(df['date'].dt.hour).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df1 = dfC\n",
    "\n",
    "# Transform trip duration from second to minutes\n",
    "df1['tripD'] = df1['tripduration'][(df1['date'].dt.hour >= 8) & (df1['date'].dt.hour < 20)] / 60\n",
    "df1['tripN'] = df1['tripduration'][(df1['date'].dt.hour < 8) | (df1['date'].dt.hour >= 20)] / 60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df1.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df1.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df1 = df1.drop([u'tripduration', u'starttime', u'stoptime', u'start station id',\n",
    "       u'start station name', u'start station latitude',\n",
    "       u'start station longitude', u'end station id', u'end station name',\n",
    "       u'end station latitude', u'end station longitude', u'bikeid',\n",
    "       u'usertype', u'birth year', u'gender', u'date', \n",
    "       ],axis=1)\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df1.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df1.dropna(how='all',inplace= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df1.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# plotting histogramswith pandas is a bit different than with pylab\n",
    "# this is a VERY USEFUL syntaxfor you to knonw!\n",
    "bins = np.arange(0,90,5)\n",
    "axD = df1.tripD.groupby(pd.cut(df1.tripD, bins)).agg([count_nonzero]).plot(kind='bar', \n",
    "                                                                legend=False)\n",
    "axD.set_title(\"trip duration during the day\")\n",
    "axN = df1.tripN.groupby(pd.cut(df1.tripN, bins)).agg([count_nonzero]).plot(kind='bar',\n",
    "                                                                legend=False)\n",
    "axN.set_title(\"trip duration during the night\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#print df.ageS, df.ageS.cumsum()\n",
    "\n",
    "csD=df1.tripD.groupby(pd.cut(df1.tripD, bins)).agg([count_nonzero]).cumsum()\n",
    "\n",
    "csN=df1.tripN.groupby(pd.cut(df1.tripN, bins)).agg([count_nonzero]).cumsum() \n",
    "\n",
    "print (np.abs(csD / csD.max()-csN / csN.max()))\n",
    "\n",
    "pl.plot(bins[:-1] + 5, csD / csD.max(), label = \"D\")\n",
    "pl.plot(bins[:-1] + 5, csN / csN.max(), label = \"N\")\n",
    "pl.plot(bins[:-1] + 5, np.sqrt(csN / csN.max() - csD / csD.max())**2, 'k-',\n",
    "        label = \"difference\")\n",
    "pl.xlabel(\"Trip Duration\")\n",
    "pl.ylabel(\"Normalized Cumulative Number\")\n",
    "pl.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 KS test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ks = scipy.stats.ks_2samp(df1.tripD, df1.tripN)\n",
    "print (ks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Discussion:\n",
    "**statistic = 0.5238**    \n",
    "**p-value = 0.0**    \n",
    "**Result: reject the null hypothesis because the p-value is below critical value 0.05.** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Redo the KS test with reducted dataset (a subset 200 times smaller)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df1_sub = df1.sample(n=int(len(df1)/200),random_state=500)\n",
    "len(df1_sub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ks_sub = scipy.stats.ks_2samp(df1_sub.tripD, df1_sub.tripN)\n",
    "print (ks_sub)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discussion:\n",
    "**KS statistic = 0.5276**    \n",
    "**p-value = 0.0**         \n",
    "**We can reject the null hypothesis since the p-value is below 0.05.***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Pearson's test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pr = scipy.stats.pearsonr(df1_sub.TripDay,df1_sub.TripNight)\n",
    "print(pr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Discussion:\n",
    "**Pearson's correlation coefficient = 0.8925**  \n",
    "**the p-value = 0.0**     \n",
    "**Result: The null hypothesis is rejected because the p-value is less than 0.05.**  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 Spearman's test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sr = scipy.stats.spearmanr(df1_sub.TripDay, df1_sub.TripNight)\n",
    "print(sr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Discussion:\n",
    "**Spearman's correlation coefficient = 0.99999933283798148**  \n",
    "**the p-value = 0.0**  \n",
    "**Result: The null hypothesis is rejected because the p-value is less than 0.05.**  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2: age of bikers for trips originating in Manhattan and in Brooklyn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "PUI2016_Python2",
   "language": "python",
   "name": "pui2016_python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "135px",
    "width": "251px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
